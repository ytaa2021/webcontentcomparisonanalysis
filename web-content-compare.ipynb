{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Company                                      Homepage Text\n",
      "0     Seclore  What If …\\nData Carries Its Own\\nSecurity & Pr...\n",
      "1      Citrix  Support any user, anywhere \\nMeet the evolving...\n",
      "2       Axway  Announcing a new kind of API marketplace. Your...\n",
      "3  GoAnywhere  Simplify and Secure File Transfers with the #1...\n",
      "4     PreVeil  Simple, encrypted document collaboration and e...\n",
      "5      Egress  People and technology aren’t a perfect mix.\\nW...\n",
      "6      Egnyte  Secure Enterprise File Sharing\\nSTART FREE TRI...\n",
      "7    Echoworx  Home\\nOnly Echoworx customizable encryption of...\n",
      "8   Kiteworks  \\nLeverage content-defined zero trust to unify...\n",
      "0       Seclore\n",
      "1        Citrix\n",
      "2         Axway\n",
      "3    GoAnywhere\n",
      "4       PreVeil\n",
      "5        Egress\n",
      "6        Egnyte\n",
      "7      Echoworx\n",
      "8     Kiteworks\n",
      "Name: Company, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#TFIDF - good for contrasting differences.\n",
    "#Still need to work on BoW to compare similarities.\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "file = r\"C:\\Users\\yotam.twersky\\Downloads\\Competitor Content.csv\"\n",
    "error_lines_bad = False\n",
    "df = pd.read_csv(file)\n",
    "print (df.head(10))\n",
    "print (df['Company'])\n",
    "filename = r\"C:\\Users\\yotam.twersky\\Downloads\\OneDrive_1_1-31-2023\\companal1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yotam.twersky\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\Users\\yotam.twersky\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "docs=list(df['Homepage Text'])\n",
    "#instantiate CountVectorizer() \n",
    "cv=CountVectorizer() \n",
    "# this steps generates word counts for the words in your docs \n",
    "word_count_vector=cv.fit_transform(docs)\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True) \n",
    "tfidf_transformer.fit(word_count_vector)\n",
    "df_idf = pd.DataFrame(tfidf_transformer.idf_, index=cv.get_feature_names(),columns=[\"idf_weights\"]) \n",
    "# sort ascending \n",
    "df_idf.sort_values(by=['idf_weights'])\n",
    "# count matrix \n",
    "count_vector=cv.transform(docs) \n",
    "# tf-idf scores \n",
    "tf_idf_vector=tfidf_transformer.transform(count_vector)\n",
    "\n",
    "feature_names = cv.get_feature_names() \n",
    "#get tfidf vector for first document \n",
    "#print the scores \n",
    "tfidfdict = {}\n",
    "complist = []\n",
    "for i in range(len(df['Company'])):\n",
    "    seclore_vector=tf_idf_vector[i]\n",
    "    seclore_df_tfidf = pd.DataFrame(seclore_vector.T.todense(), index=feature_names, columns=[\"tfidf\"]) \n",
    "    company = df['Company'][i]\n",
    "    resultsn = seclore_df_tfidf.sort_values(by=[\"tfidf\"],ascending=False)\n",
    "    resultsn['Company'] = company\n",
    "    complist.append(resultsn)\n",
    "tfidfresult = pd.concat(complist)\n",
    "tfidfresult.to_csv(filename, index=True, header=True, columns=[\"tfidf\",\"Company\"])\n",
    "\n",
    "filename = r\"C:\\Users\\yotam.twersky\\Downloads\\OneDrive_1_1-31-2023\\companal2.csv\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #for row in resultsn.index:\n",
    "    #    complist.append(row)\n",
    "    #tfidfdict[company] = complist\n",
    "#print(tfidfdict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "1180\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import csv\n",
    "filename = r\"C:\\Users\\yotam.twersky\\Downloads\\OneDrive_1_1-31-2023\\companal2.csv\"\n",
    "\n",
    "\n",
    "print(len(df['Company']))\n",
    "vocabulary = cv.vocabulary_\n",
    "bag_of_words = word_count_vector.toarray()\n",
    "\n",
    "print(vocabulary['what'])\n",
    "\n",
    "\n",
    "\n",
    "newdict = {}\n",
    "for key in vocabulary:\n",
    "    newdict[key] = []\n",
    "    for i in range(len(df['Company'])):\n",
    "        newdict[key].append(bag_of_words[i][vocabulary.get(key)])\n",
    "\n",
    "\n",
    "with open(filename, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Key'] + [df['Company'][i] for i in range(len(df['Company']))])\n",
    "    for key, value in newdict.items():\n",
    "        writer.writerow([key] + value)\n",
    "\n",
    "filename = r\"C:\\Users\\yotam.twersky\\Downloads\\OneDrive_1_1-31-2023\\companal3.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\yotam.twersky\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"vader_lexicon\")\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "sentiment_scores = []\n",
    "for document in range(len(docs)):\n",
    "    sentiment_scores.append([\n",
    "        df['Company'][document],\n",
    "        sia.polarity_scores(docs[document])[\"neg\"],\n",
    "        sia.polarity_scores(docs[document])[\"neu\"],\n",
    "        sia.polarity_scores(docs[document])[\"pos\"],\n",
    "        sia.polarity_scores(docs[document])[\"compound\"]\n",
    "    ])\n",
    "\n",
    "with open(filename, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"Company Name\", \"Neg\", \"Neu\", \"Pos\", \"Compound\"])\n",
    "    for sentiment_score in sentiment_scores:\n",
    "        writer.writerow(sentiment_score)\n",
    "\n",
    "\n",
    "filename = r\"C:\\Users\\yotam.twersky\\Downloads\\OneDrive_1_1-31-2023\\companal4.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('Seclore', 'Citrix'): 0.14990580652419477, ('Seclore', 'Axway'): 0.12413230258819968, ('Seclore', 'GoAnywhere'): 0.1739847232200147, ('Seclore', 'PreVeil'): 0.17771649234300746, ('Seclore', 'Egress'): 0.12265145936923318, ('Seclore', 'Egnyte'): 0.14013983577745398, ('Seclore', 'Echoworx'): 0.16272896210031731, ('Seclore', 'Kiteworks'): 0.18205010401359015, ('Citrix', 'Axway'): 0.2566609771165778, ('Citrix', 'GoAnywhere'): 0.30020038564541807, ('Citrix', 'PreVeil'): 0.2232318793800678, ('Citrix', 'Egress'): 0.12119934458619572, ('Citrix', 'Egnyte'): 0.21946003177150814, ('Citrix', 'Echoworx'): 0.3159430875540551, ('Citrix', 'Kiteworks'): 0.26589385471407323, ('Axway', 'GoAnywhere'): 0.28538406970825264, ('Axway', 'PreVeil'): 0.192352730351954, ('Axway', 'Egress'): 0.12063686574684403, ('Axway', 'Egnyte'): 0.20141779773759022, ('Axway', 'Echoworx'): 0.2971330972196313, ('Axway', 'Kiteworks'): 0.273744965815279, ('GoAnywhere', 'PreVeil'): 0.2665760017735616, ('GoAnywhere', 'Egress'): 0.14417521992229007, ('GoAnywhere', 'Egnyte'): 0.2981393773613141, ('GoAnywhere', 'Echoworx'): 0.3623034858759517, ('GoAnywhere', 'Kiteworks'): 0.3447942412940156, ('PreVeil', 'Egress'): 0.13447303915756992, ('PreVeil', 'Egnyte'): 0.21254365683060095, ('PreVeil', 'Echoworx'): 0.2842406819089093, ('PreVeil', 'Kiteworks'): 0.28839806741970503, ('Egress', 'Egnyte'): 0.11231878158988795, ('Egress', 'Echoworx'): 0.17296864046575391, ('Egress', 'Kiteworks'): 0.14657604117672138, ('Egnyte', 'Echoworx'): 0.28830858715558755, ('Egnyte', 'Kiteworks'): 0.32617588352052235, ('Echoworx', 'Kiteworks'): 0.2864625068829447}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(docs)\n",
    "\n",
    "cosine_similarities = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "cosine_similarities_dict = {}\n",
    "for i in range(len(docs)):\n",
    "    for j in range(i+1, len(docs)):\n",
    "        cosine_similarities_dict[(df['Company'][i], df['Company'][j])] = cosine_similarities[i][j]\n",
    "\n",
    "print(cosine_similarities_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"Company 1\", \"Company 2\", \"Cosine Similarity\"])\n",
    "    for indices, score in cosine_similarities_dict.items():\n",
    "        writer.writerow([indices[0], indices[1], score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9908a25b1f193db655f14c7b61033190f2decefa17949bc937d1abc7d11a88e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
